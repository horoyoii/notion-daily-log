#!/usr/bin/env python3
"""
ë‹¨ì¼ í˜ì´ì§€ ì•„ì¹´ì´ë¸Œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì‚¬ìš©ìê°€ ì§ì ‘ í˜ì´ì§€ IDë‚˜ ì œëª©ì„ ì§€ì •í•˜ì—¬ ë‹¨ì¼ í˜ì´ì§€ë¥¼ ì•„ì¹´ì´ë¸Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

import os
import sys
import requests
import json
import argparse
import logging
from typing import Optional
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


class NotionSinglePageArchiver:
    """Notion ë‹¨ì¼ í˜ì´ì§€ ì•„ì¹´ì´ë¸Œ"""

    def __init__(self, api_key: str, database_id: str, archive_page_id: str):
        self.api_key = api_key
        self.database_id = database_id
        self.archive_page_id = archive_page_id
        self.base_url = "https://api.notion.com/v1"
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
            "Notion-Version": "2022-06-28"
        }

    def get_page_blocks(self, page_id: str) -> list:
        """í˜ì´ì§€ì˜ ëª¨ë“  ë¸”ë¡ ê°€ì ¸ì˜¤ê¸° (í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬)"""
        url = f"{self.base_url}/blocks/{page_id}/children"
        all_blocks = []
        
        try:
            has_more = True
            start_cursor = None
            
            while has_more:
                params = {}
                if start_cursor:
                    params['start_cursor'] = start_cursor
                
                response = requests.get(url, headers=self.headers, params=params)
                response.raise_for_status()
                
                data = response.json()
                all_blocks.extend(data.get('results', []))
                has_more = data.get('has_more', False)
                start_cursor = data.get('next_cursor')
            
            return all_blocks
            
        except requests.exceptions.RequestException as e:
            logger.error(f"ë¸”ë¡ ì½˜í…ì¸  ì¡°íšŒ ì‹¤íŒ¨ ({page_id}): {e}")
            return []

    def get_child_pages(self, page_id: str) -> list:
        """í˜ì´ì§€ì˜ ëª¨ë“  í•˜ìœ„ í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°"""
        url = f"{self.base_url}/blocks/{page_id}/children"
        child_pages = []
        
        try:
            has_more = True
            start_cursor = None
            
            while has_more:
                params = {}
                if start_cursor:
                    params['start_cursor'] = start_cursor
                
                response = requests.get(url, headers=self.headers, params=params)
                response.raise_for_status()
                
                data = response.json()
                blocks = data.get('results', [])
                
                for block in blocks:
                    if block.get('type') == 'child_page':
                        child_pages.append(block)
                
                has_more = data.get('has_more', False)
                start_cursor = data.get('next_cursor')
            
            return child_pages
            
        except requests.exceptions.RequestException as e:
            logger.error(f"í•˜ìœ„ í˜ì´ì§€ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return []

    def create_page(self, parent_id: str, title: str) -> Optional[str]:
        """ì§€ì •ëœ ë¶€ëª¨ ì•„ë˜ì— ìƒˆ í˜ì´ì§€ë¥¼ ë§Œë“­ë‹ˆë‹¤."""
        url = f"{self.base_url}/pages"
        payload = {
            "parent": {"page_id": parent_id},
            "properties": {
                "title": {
                    "title": [{"type": "text", "text": {"content": title}}]
                }
            }
        }
        try:
            response = requests.post(url, headers=self.headers, json=payload)
            response.raise_for_status()
            new_page_id = response.json()['id']
            logger.info(f"  ğŸ“„ ìƒˆ í˜ì´ì§€ ìƒì„± ì™„ë£Œ: {title} (ID: {new_page_id})")
            return new_page_id
        except requests.exceptions.RequestException as e:
            logger.error(f"ìƒˆ í˜ì´ì§€ ìƒì„± ì‹¤íŒ¨ ({title}): {e}")
            if hasattr(e.response, 'text'):
                logger.error(f"   ì‘ë‹µ: {e.response.text}")
            return None

    def clean_block_for_copy(self, block: dict) -> dict:
        """ë¸”ë¡ ë°ì´í„°ë¥¼ ë³µì‚¬ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ë¦¬"""
        block_type = block.get('type')
        if not block_type:
            return None
        
        if block_type in ['child_page', 'child_database']:
            return None
        
        unsupported_blocks = ['link_preview', 'unsupported']
        if block_type in unsupported_blocks:
            logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸”ë¡ íƒ€ì…: {block_type}")
            return None
        
        cleaned_block = {
            'type': block_type,
            block_type: {}
        }
        
        original_content = block.get(block_type, {})
        
        empty_block_types = ['divider', 'breadcrumb', 'table_of_contents']
        if block_type in empty_block_types:
            return cleaned_block
        
        if 'rich_text' in original_content:
            cleaned_block[block_type]['rich_text'] = original_content['rich_text']
        
        readonly_fields = ['id', 'created_time', 'last_edited_time', 'created_by', 'last_edited_by', 'has_children', 'archived', 'parent']
        for key, value in original_content.items():
            if key not in readonly_fields and key not in cleaned_block[block_type]:
                cleaned_block[block_type][key] = value
        
        return cleaned_block

    def copy_block_children(self, source_block_id: str, target_block_id: str):
        """ë¸”ë¡ì˜ ìì‹ ë¸”ë¡ë“¤ì„ ì¬ê·€ì ìœ¼ë¡œ ë³µì‚¬"""
        child_blocks = self.get_page_blocks(source_block_id)
        if not child_blocks:
            return
        self.copy_blocks_to_page(target_block_id, child_blocks)

    def copy_blocks_to_page(self, target_page_id: str, blocks: list):
        """ë¸”ë¡ë“¤ì„ ëŒ€ìƒ í˜ì´ì§€ë¡œ ìˆœì„œëŒ€ë¡œ ë³µì‚¬ (ì¼ë°˜ ë¸”ë¡ + child_page í¬í•¨)"""
        if not blocks:
            return
        
        import time
        logger.info(f"  ë¸”ë¡ ë³µì‚¬ ì‹œì‘: {len(blocks)}ê°œ (ìˆœì„œ ìœ ì§€)")
        
        for block in blocks:
            block_type = block.get('type')
            
            if block_type == 'child_page':
                child_title = block.get('child_page', {}).get('title', 'ì œëª© ì—†ìŒ')
                logger.info(f"  í•˜ìœ„ í˜ì´ì§€ ë°œê²¬ (ìˆœì„œ ìœ ì§€): {child_title}")
                time.sleep(0.5)
                try:
                    self.copy_child_page_recursive(block['id'], target_page_id)
                except Exception as e:
                    logger.error(f"  í•˜ìœ„ í˜ì´ì§€ ë³µì‚¬ ì‹¤íŒ¨: {str(e)}")
                continue
            
            if block_type == 'child_database':
                logger.warning(f"  child_databaseëŠ” í˜„ì¬ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {block['id']}")
                continue
            
            cleaned_block = self.clean_block_for_copy(block)
            if not cleaned_block:
                continue
            
            url = f"{self.base_url}/blocks/{target_page_id}/children"
            payload = {"children": [cleaned_block]}
            
            try:
                response = requests.patch(url, headers=self.headers, json=payload)
                response.raise_for_status()
                
                result = response.json()
                created_blocks = result.get('results', [])
                
                if created_blocks:
                    created_block = created_blocks[0]
                    
                    if block.get('has_children'):
                        original_block_id = block['id']
                        created_block_id = created_block['id']
                        time.sleep(0.3)
                        try:
                            self.copy_block_children(original_block_id, created_block_id)
                        except Exception as e:
                            logger.error(f"  ì¤‘ì²© ë¸”ë¡ ë³µì‚¬ ì‹¤íŒ¨: {str(e)}")
                
                time.sleep(0.3)
                
            except requests.exceptions.RequestException as e:
                logger.error(f"  ë¸”ë¡ ë³µì‚¬ ì‹¤íŒ¨ ({block_type}): {str(e)}")

    def copy_child_page_recursive(self, source_page_id: str, target_parent_id: str):
        """í•˜ìœ„ í˜ì´ì§€ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ë³µì‚¬"""
        import time
        
        try:
            url = f"{self.base_url}/pages/{source_page_id}"
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            
            source_page = response.json()
            
            title_property = source_page.get('properties', {}).get('title', {})
            title_array = title_property.get('title', [])
            title = title_array[0].get('text', {}).get('content', 'ì œëª© ì—†ìŒ') if title_array else 'ì œëª© ì—†ìŒ'
            
            logger.info(f"    í•˜ìœ„ í˜ì´ì§€ ë³µì‚¬ ì‹œì‘: {title}")
            
            new_page_id = self.create_page(target_parent_id, title)
            if not new_page_id:
                return
            
            time.sleep(0.5)
            
            source_blocks = self.get_page_blocks(source_page_id)
            if source_blocks:
                self.copy_blocks_to_page(new_page_id, source_blocks)
            
            time.sleep(0.5)
            
            child_pages = self.get_child_pages(source_page_id)
            for child_page in child_pages:
                child_page_id = child_page['id']
                time.sleep(0.5)
                self.copy_child_page_recursive(child_page_id, new_page_id)
            
            logger.info(f"    í•˜ìœ„ í˜ì´ì§€ ë³µì‚¬ ì™„ë£Œ: {title}")
            
        except Exception as e:
            logger.error(f"    í•˜ìœ„ í˜ì´ì§€ ë³µì‚¬ ì‹¤íŒ¨: {str(e)}")

    def find_page_by_id(self, page_id: str) -> Optional[dict]:
        """í˜ì´ì§€ IDë¡œ í˜ì´ì§€ ì°¾ê¸°"""
        url = f"{self.base_url}/pages/{page_id}"
        try:
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            logger.error(f"í˜ì´ì§€ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return None

    def find_page_by_title(self, title: str) -> Optional[dict]:
        """í˜ì´ì§€ ì œëª©ìœ¼ë¡œ í˜ì´ì§€ ì°¾ê¸°"""
        url = f"{self.base_url}/databases/{self.database_id}/query"
        payload = {
            "filter": {
                "property": "ì´ë¦„",
                "title": {
                    "equals": title
                }
            }
        }
        
        try:
            response = requests.post(url, headers=self.headers, json=payload)
            response.raise_for_status()
            
            results = response.json().get('results', [])
            if results:
                return results[0]
            return None
        except requests.exceptions.RequestException as e:
            logger.error(f"í˜ì´ì§€ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return None

    def get_page_title(self, page: dict) -> str:
        """í˜ì´ì§€ì—ì„œ ì œëª© ì¶”ì¶œ"""
        title_property = page.get('properties', {}).get('ì´ë¦„', {})
        title_array = title_property.get('title', [])
        if title_array:
            return title_array[0].get('text', {}).get('content', 'ì œëª© ì—†ìŒ')
        return 'ì œëª© ì—†ìŒ'

    def delete_page(self, page_id: str, page_title: str) -> bool:
        """í˜ì´ì§€ë¥¼ ë³´ê´€ ì²˜ë¦¬í•˜ì—¬ ì‚­ì œí•©ë‹ˆë‹¤."""
        url = f"{self.base_url}/pages/{page_id}"
        payload = {"archived": True}
        try:
            response = requests.patch(url, headers=self.headers, json=payload)
            response.raise_for_status()
            logger.info(f"  ğŸ—‘ï¸ ì›ë³¸ í˜ì´ì§€ ë³´ê´€ ì™„ë£Œ: {page_title}")
            return True
        except requests.exceptions.RequestException as e:
            logger.error(f"ì›ë³¸ í˜ì´ì§€ ë³´ê´€ ì‹¤íŒ¨ ({page_title}): {e}")
            return False

    def archive_page(self, page_id: str, page_title: str) -> bool:
        """í˜ì´ì§€ë¥¼ ì•„ì¹´ì´ë¸Œí•©ë‹ˆë‹¤."""
        import time
        logger.info(f"í˜ì´ì§€ ì•„ì¹´ì´ë¸Œ ì‹œì‘: {page_title}")

        # 1. ì›ë³¸ í˜ì´ì§€ì˜ ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸°
        content_blocks = self.get_page_blocks(page_id)
        logger.info(f"  ğŸ“š ì›ë³¸ ì½˜í…ì¸  {len(content_blocks)}ê°œ ë¸”ë¡ ì½ê¸° ì™„ë£Œ")

        # 2. ì•„ì¹´ì´ë¸Œ í˜ì´ì§€ ì•„ë˜ì— ìƒˆ í˜ì´ì§€ ìƒì„±
        new_page_id = self.create_page(self.archive_page_id, page_title)
        if not new_page_id:
            return False

        time.sleep(0.5)

        # 3. ì½˜í…ì¸  ë³µì‚¬ (ìˆœì„œ ìœ ì§€, í•˜ìœ„ í˜ì´ì§€ í¬í•¨)
        if content_blocks:
            self.copy_blocks_to_page(new_page_id, content_blocks)
        logger.info(f"  âœ… ì½˜í…ì¸  ë³µì‚¬ ì™„ë£Œ")

        # 4. í•˜ìœ„ í˜ì´ì§€ë„ ì¬ê·€ì ìœ¼ë¡œ ë³µì‚¬
        child_pages = self.get_child_pages(page_id)
        if child_pages:
            logger.info(f"  ğŸ“ í•˜ìœ„ í˜ì´ì§€ {len(child_pages)}ê°œ ë°œê²¬, ì¬ê·€ ë³µì œ ì‹œì‘")
            for child_page in child_pages:
                child_page_id = child_page['id']
                time.sleep(0.5)
                self.copy_child_page_recursive(child_page_id, new_page_id)
            logger.info(f"  âœ… í•˜ìœ„ í˜ì´ì§€ ë³µì œ ì™„ë£Œ")

        # 5. ì›ë³¸ í˜ì´ì§€ ì‚­ì œ
        if not self.delete_page(page_id, page_title):
            logger.error(f"ì›ë³¸ í˜ì´ì§€({page_id}) ì‚­ì œ ì‹¤íŒ¨. ìˆ˜ë™ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return False
        
        logger.info(f"âœ… ì•„ì¹´ì´ë¸Œ ì™„ë£Œ: {page_title}")
        return True


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ë‹¨ì¼ í˜ì´ì§€ ì•„ì¹´ì´ë¸Œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸')
    parser.add_argument('--page-id', type=str, help='ì•„ì¹´ì´ë¸Œí•  í˜ì´ì§€ ID')
    parser.add_argument('--page-title', type=str, help='ì•„ì¹´ì´ë¸Œí•  í˜ì´ì§€ ì œëª©')
    
    args = parser.parse_args()
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ
    api_key = os.getenv('NOTION_API_KEY')
    database_id = os.getenv('DATA_SOURCE_ID')
    archive_page_id = os.getenv('ARCHIVE_PAGE_ID', '1cb5aae782eb807c81cef3bd6e2345ee')
    
    # ëª…ë ¹ì¤„ ì¸ìê°€ ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
    page_id = args.page_id or os.getenv('PAGE_ID')
    page_title = args.page_title or os.getenv('PAGE_TITLE')
    
    # í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ í™•ì¸
    if not all([api_key, database_id]):
        logger.error("í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        logger.error("NOTION_API_KEY, DATA_SOURCE_IDë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        sys.exit(1)
    
    # í˜ì´ì§€ ID ë˜ëŠ” ì œëª© í™•ì¸
    if not page_id and not page_title:
        logger.error("í˜ì´ì§€ ID ë˜ëŠ” ì œëª©ì„ ì§€ì •í•´ì£¼ì„¸ìš”.")
        logger.error("ì‚¬ìš©ë²•:")
        logger.error("  python archive_single_page.py --page-id <page_id>")
        logger.error("  python archive_single_page.py --page-title \"2026ë…„ 12ì›” 15ì¼ (ì›”)\"")
        logger.error("  ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ PAGE_ID ë˜ëŠ” PAGE_TITLE ì„¤ì •")
        sys.exit(1)
    
    # ì•„ì¹´ì´ë²„ ìƒì„±
    archiver = NotionSinglePageArchiver(api_key, database_id, archive_page_id)
    
    # í˜ì´ì§€ ì°¾ê¸°
    page = None
    page_id_to_archive = None
    page_title_to_archive = None
    
    if page_id:
        logger.info(f"í˜ì´ì§€ IDë¡œ ê²€ìƒ‰: {page_id}")
        page = archiver.find_page_by_id(page_id)
        if page:
            page_id_to_archive = page_id
            page_title_to_archive = archiver.get_page_title(page)
        else:
            logger.error(f"í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {page_id}")
            sys.exit(1)
    elif page_title:
        logger.info(f"í˜ì´ì§€ ì œëª©ìœ¼ë¡œ ê²€ìƒ‰: {page_title}")
        page = archiver.find_page_by_title(page_title)
        if page:
            page_id_to_archive = page['id']
            page_title_to_archive = page_title
        else:
            logger.error(f"í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {page_title}")
            sys.exit(1)
    
    # ì•„ì¹´ì´ë¸Œ ì‹¤í–‰
    logger.info("=" * 80)
    logger.info("ë‹¨ì¼ í˜ì´ì§€ ì•„ì¹´ì´ë¸Œ ì‹œì‘")
    logger.info("=" * 80)
    logger.info(f"í˜ì´ì§€ ID: {page_id_to_archive}")
    logger.info(f"í˜ì´ì§€ ì œëª©: {page_title_to_archive}")
    logger.info(f"ì•„ì¹´ì´ë¸Œ ëŒ€ìƒ: https://www.notion.so/{archive_page_id.replace('-', '')}\n")
    
    if archiver.archive_page(page_id_to_archive, page_title_to_archive):
        logger.info("\n" + "=" * 80)
        logger.info("ì•„ì¹´ì´ë¸Œ ì„±ê³µ!")
        logger.info("=" * 80)
    else:
        logger.error("\n" + "=" * 80)
        logger.error("ì•„ì¹´ì´ë¸Œ ì‹¤íŒ¨!")
        logger.error("=" * 80)
        sys.exit(1)


if __name__ == "__main__":
    main()

